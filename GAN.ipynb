{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2645,
     "status": "ok",
     "timestamp": 1544732500213,
     "user": {
      "displayName": "Lalit Sachan",
      "photoUrl": "https://lh3.googleusercontent.com/-QD6-pZD3z7U/AAAAAAAAAAI/AAAAAAAAAdQ/rjkTd5fbuZc/s64/photo.jpg",
      "userId": "01076966828418651230"
     },
     "user_tz": -330
    },
    "id": "pGugoFvXOqRa",
    "outputId": "37443fff-0ab3-47d2-a150-b28157efd8cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1216,
     "status": "ok",
     "timestamp": 1544732531984,
     "user": {
      "displayName": "Lalit Sachan",
      "photoUrl": "https://lh3.googleusercontent.com/-QD6-pZD3z7U/AAAAAAAAAAI/AAAAAAAAAdQ/rjkTd5fbuZc/s64/photo.jpg",
      "userId": "01076966828418651230"
     },
     "user_tz": -330
    },
    "id": "KzYSUeihO1Zo",
    "outputId": "88fa2142-a865-4168-fffa-bf84ecbe4fe5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fwdcertificatesall',\n",
       " 'mobilenet_1_0_224_tf_no_top.h5',\n",
       " 'class2912.ipynb',\n",
       " 'Decision Trees  Random Forest Class  (1).ipynb',\n",
       " 'checkApp.ipynb',\n",
       " 'rc2.jpeg',\n",
       " 'Decision Trees  Random Forest Reading.ipynb',\n",
       " 'Codes (1).zip',\n",
       " 'Stacking , pIplines and python data products.pdf',\n",
       " 'mnist_data.zip',\n",
       " 'Intro to ML.ipynb',\n",
       " '3. Tensorboard with Keras.ipynb',\n",
       " 'Project_1_RealEstate (1).R',\n",
       " 'Clustering Reading.ipynb',\n",
       " 'model.h5',\n",
       " 'Unsupervised Deep Learning .pdf',\n",
       " 'Boosting Machines (2).ipynb',\n",
       " 'Linear Models Reading.ipynb',\n",
       " 'WhatsApp Image 2018-11-21 at 6.13.12 PM.jpeg',\n",
       " 'KNN SVM NB with Text Data.pdf',\n",
       " 'Data preparation codes (1).zip',\n",
       " 'Banking Project.R',\n",
       " '6. Classifying with generic Images.ipynb',\n",
       " 'resized',\n",
       " 'Anaconda3-5.3.0-Linux-x86_64.sh',\n",
       " 'fullaadhaarimage.jpg',\n",
       " 'KNN, SVM , NB and text data.ipynb',\n",
       " '2. Transfer Learning.ipynb',\n",
       " 'Convolution Neural Network.pdf',\n",
       " 'hirens-bootcd-15-2-es-en-win (1).zip',\n",
       " 'Codes.zip',\n",
       " 'R Fundamentals_ClassCode.R',\n",
       " 'Linear Models.ipynb',\n",
       " 'YKM0496364.pdf',\n",
       " 'rc1.jpeg',\n",
       " 'Copy of SAI.jpg',\n",
       " '2.1 CNN with Keras (1).ipynb',\n",
       " 'Boosting Machines (1).ipynb',\n",
       " 'Boosting Machines.ipynb',\n",
       " 'Python Codes For Stacking, Pipline and Flask API.zip',\n",
       " 'sai.pdf',\n",
       " '2.Gradient Descent and its variants.pdf',\n",
       " 'EMPOLYMENT CARD.jpg',\n",
       " 'rufus-3.4_arm.exe',\n",
       " 'genymotion-2.12.2-vbox.(SoftAlien.co).exe',\n",
       " 'model.json',\n",
       " '0. Gradient Descent and it variants .ipynb',\n",
       " '2. Action Sequence with Keras.ipynb',\n",
       " 'Decision Trees  Random Forest Class .ipynb',\n",
       " 'Deep Autoencoder.ipynb',\n",
       " 'GAN.ipynb',\n",
       " '3.Text Classification with Keras (1).ipynb',\n",
       " 'fwdcertificatesall.zip',\n",
       " '.ipynb_checkpoints',\n",
       " 'genymotion',\n",
       " 'Boosting Machines.pdf',\n",
       " 'Download Data.zip',\n",
       " 'KNN SVM Class Reading.ipynb',\n",
       " 'Screenshot from 2018-11-21 18-34-53.png',\n",
       " 'mytree.dot',\n",
       " 'Recurrent Neural Network.pdf',\n",
       " 'unetbootin-linux64-661.bin',\n",
       " 'Rufus-3.4.appx',\n",
       " 'Basic ML codes.zip',\n",
       " 'census_income.csv',\n",
       " 'hirens-bootcd-15-2-es-en-win.zip',\n",
       " '1.0TensorFlow Basics.ipynb',\n",
       " '420032707.pdf',\n",
       " 'PAN.jpeg',\n",
       " 'Text_Mining_Web_Scraping',\n",
       " '1.2 CNN with Tensorflow (1).ipynb',\n",
       " 'rufus-usb-3-3.exe',\n",
       " 'virtualbox-6.0_6.0.0-127566_Ubuntu_xenial_amd64.deb',\n",
       " 'mnist_data',\n",
       " '1.1 Deep Feed Forward Networks With Tensroflow (1).ipynb',\n",
       " '1.1 Deep Feed Forward Networks With Tensroflow.ipynb',\n",
       " 'genymotion-3.0.0-linux_x64.bin',\n",
       " 'CandidateHallTicket.pdf',\n",
       " 'Unsupervised Learning.pdf',\n",
       " 'Neural Net (1).ipynb',\n",
       " 'Python Codes for Quick understanding videos.zip',\n",
       " 'class1201s.ipynb',\n",
       " 'train-labels-idx1-ubyte',\n",
       " '1. Hybrid Architectures with Keras.ipynb',\n",
       " 'Neural Net.ipynb',\n",
       " '1. Numeric Time Series with LSTM (1).ipynb',\n",
       " 'WhatsApp Image 2018-11-21 at 6.13.12 PM (1).jpeg',\n",
       " '2. Action Sequence with Keras (1).ipynb',\n",
       " 'Data.zip',\n",
       " 'my_first_file.txt',\n",
       " '2.1 CNN with Keras.ipynb',\n",
       " '1. Numeric Time Series with LSTM.ipynb',\n",
       " 'IMG-2482.JPG',\n",
       " '2.0 Introduction to Keras (1).ipynb',\n",
       " '2.0 Introduction to Keras.ipynb',\n",
       " '4. Keras Callbacks.ipynb',\n",
       " 'Dtrees , RandomForest and ExtraTrees.pdf',\n",
       " 'Python Codes for Quick understanding videos (1).zip',\n",
       " 'unetbootin-linux-661.bin',\n",
       " 'WhatsApp Image 2018-11-27 at 10.11.11 AM.jpeg',\n",
       " '3.Text Classification with Keras.ipynb',\n",
       " 'Codes (1)',\n",
       " '1.2 CNN with Tensorflow.ipynb',\n",
       " 'KNN, SVM , NB and text data (1).ipynb',\n",
       " 'Saikumar_Introduction.docx',\n",
       " 'rufus-3.4_arm64.exe',\n",
       " 'Data preparation codes.zip',\n",
       " 'Text_Mining_Web_Scraping.zip',\n",
       " 'Rufus-3.4.appx_FILES',\n",
       " 'Convolution Neural Network (1).pdf',\n",
       " 'sai-unlocked.pdf',\n",
       " 'Neural Networks.pdf',\n",
       " 'Python Codes For Stacking, Pipline and Flask API',\n",
       " 'PMTPET.pdf',\n",
       " '5. Working with google Colab.ipynb',\n",
       " 'rstudio-xenial-1.1.456-amd64.deb',\n",
       " 'Reuters Data.zip']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5799,
     "status": "ok",
     "timestamp": 1544732554688,
     "user": {
      "displayName": "Lalit Sachan",
      "photoUrl": "https://lh3.googleusercontent.com/-QD6-pZD3z7U/AAAAAAAAAAI/AAAAAAAAAdQ/rjkTd5fbuZc/s64/photo.jpg",
      "userId": "01076966828418651230"
     },
     "user_tz": -330
    },
    "id": "EqnyYAcrO9gi",
    "outputId": "9838d817-19fb-453c-ab5f-a0011727aa46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-mnist in /home/saikumar/anaconda3/lib/python3.6/site-packages (0.6)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install python-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AKDrAFB4PB7p"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "mndata = MNIST(r'mnist_data')\n",
    "images_train, _ = mndata.load_training()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aAd9u2lPV9z"
   },
   "outputs": [],
   "source": [
    "randomDim = 100\n",
    "\n",
    "# Load MNIST data\n",
    "\n",
    "images_train = (np.array(images_train).astype(np.float32) - 127.5)/127.5\n",
    "images_train = images_train.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1506,
     "status": "ok",
     "timestamp": 1544732772752,
     "user": {
      "displayName": "Lalit Sachan",
      "photoUrl": "https://lh3.googleusercontent.com/-QD6-pZD3z7U/AAAAAAAAAAI/AAAAAAAAAdQ/rjkTd5fbuZc/s64/photo.jpg",
      "userId": "01076966828418651230"
     },
     "user_tz": -330
    },
    "id": "CP5i6unZPh7f",
    "outputId": "d8f36f34-9f09-4ae7-e498-50cc94c85bad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xw5uO6RaP4No"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/saikumar/anaconda3/lib/python3.6/site-packages (3.0.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/saikumar/anaconda3/lib/python3.6/site-packages (from matplotlib) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.10.0 in /home/saikumar/anaconda3/lib/python3.6/site-packages (from matplotlib) (1.14.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/saikumar/anaconda3/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/saikumar/anaconda3/lib/python3.6/site-packages (from matplotlib) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/saikumar/anaconda3/lib/python3.6/site-packages (from matplotlib) (2.7.5)\n",
      "Requirement already satisfied: setuptools in /home/saikumar/anaconda3/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib) (40.6.3)\n",
      "Requirement already satisfied: six in /home/saikumar/anaconda3/lib/python3.6/site-packages (from cycler>=0.10->matplotlib) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-AQsdiy0P878"
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "generator = Sequential()\n",
    "generator.add(Dense(256, input_dim=randomDim, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(Dense(512))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(Dense(1024))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(Dense(784, activation='tanh'))\n",
    "generator.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UYRpI_wvQCUf"
   },
   "outputs": [],
   "source": [
    "discriminator = Sequential()\n",
    "discriminator.add(Dense(1024, input_dim=784, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Dense(512))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Dense(256))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pi3a66nQQEpM"
   },
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "ganInput = Input(shape=(randomDim,))\n",
    "x = generator(ganInput)\n",
    "ganOutput = discriminator(x)\n",
    "gan = Model(inputs=ganInput, outputs=ganOutput)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LvCW9366QI59"
   },
   "outputs": [],
   "source": [
    "def plotGeneratedImages(epoch, examples=100, dim=(10, 10), figsize=(10, 10)):\n",
    "    noise = np.random.normal(0, 1, size=[examples, randomDim])\n",
    "    generatedImages = generator.predict(noise)\n",
    "    generatedImages = generatedImages.reshape(examples, 28, 28)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generatedImages.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generatedImages[i], interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('gan_generated_image_epoch_%d.png' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CyevyaYPQNQK"
   },
   "outputs": [],
   "source": [
    "def train(epochs=1, batchSize=128):\n",
    "    batchCount = int(images_train.shape[0] / batchSize)\n",
    "    print ('Epochs:', epochs)\n",
    "    print ('Batch size:', batchSize)\n",
    "    print ('Batches per epoch:', batchCount)\n",
    "\n",
    "    for e in range(1, epochs+1):\n",
    "        print ('-'*15, 'Epoch %d' % e, '-'*15)\n",
    "        for _ in range(batchCount):\n",
    "            # Get a random set of input noise and images\n",
    "            noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n",
    "            imageBatch = images_train[np.random.randint(0, images_train.shape[0], size=batchSize)]\n",
    "\n",
    "            # Generate fake MNIST images\n",
    "            generatedImages = generator.predict(noise)\n",
    "            # print np.shape(imageBatch), np.shape(generatedImages)\n",
    "            X = np.concatenate([imageBatch, generatedImages])\n",
    "\n",
    "            # Labels for generated and real data\n",
    "            yDis = np.zeros(2*batchSize)\n",
    "            # One-sided label smoothing\n",
    "            yDis[:batchSize] = 0.9\n",
    "\n",
    "            # Train discriminator\n",
    "            discriminator.trainable = True\n",
    "            dloss = discriminator.train_on_batch(X, yDis)\n",
    "\n",
    "            # Train generator\n",
    "            noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n",
    "            yGen = np.ones(batchSize)\n",
    "            discriminator.trainable = False\n",
    "            gloss = gan.train_on_batch(noise, yGen)\n",
    "\n",
    "        \n",
    "\n",
    "        if e == 1 or e % 20 == 0:\n",
    "            plotGeneratedImages(e)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 11256
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1334478,
     "status": "ok",
     "timestamp": 1544736210919,
     "user": {
      "displayName": "Lalit Sachan",
      "photoUrl": "https://lh3.googleusercontent.com/-QD6-pZD3z7U/AAAAAAAAAAI/AAAAAAAAAdQ/rjkTd5fbuZc/s64/photo.jpg",
      "userId": "01076966828418651230"
     },
     "user_tz": -330
    },
    "id": "HjDNkGVpQwoP",
    "outputId": "30205703-8c8f-4a3a-f871-1c6aecb72b1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 200\n",
      "Batch size: 100\n",
      "Batches per epoch: 600\n",
      "--------------- Epoch 1 ---------------\n",
      "--------------- Epoch 2 ---------------\n",
      "--------------- Epoch 3 ---------------\n",
      "--------------- Epoch 4 ---------------\n",
      "--------------- Epoch 5 ---------------\n",
      "--------------- Epoch 6 ---------------\n",
      "--------------- Epoch 7 ---------------\n"
     ]
    }
   ],
   "source": [
    "train(200,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1842,
     "status": "ok",
     "timestamp": 1544736215809,
     "user": {
      "displayName": "Lalit Sachan",
      "photoUrl": "https://lh3.googleusercontent.com/-QD6-pZD3z7U/AAAAAAAAAAI/AAAAAAAAAdQ/rjkTd5fbuZc/s64/photo.jpg",
      "userId": "01076966828418651230"
     },
     "user_tz": -330
    },
    "id": "U9izAecmQ8-Y",
    "outputId": "528834fe-8ca3-402b-e681-30591c5b57ed"
   },
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EOrnOmGFX5Ep"
   },
   "outputs": [],
   "source": [
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mlqarmCidQ3m"
   },
   "outputs": [],
   "source": [
    "for f in [\n",
    " 'gan_generated_image_epoch_180.png',\n",
    " 'gan_generated_image_epoch_20.png',\n",
    " 'gan_generated_image_epoch_160.png',\n",
    " 'gan_generated_image_epoch_200.png',\n",
    " \n",
    " 'gan_generated_image_epoch_80.png',\n",
    " 'gan_generated_image_epoch_40.png',\n",
    " \n",
    " 'gan_generated_image_epoch_120.png',\n",
    " 'gan_generated_image_epoch_100.png',\n",
    " 'gan_generated_image_epoch_60.png',\n",
    " 'gan_generated_image_epoch_140.png',\n",
    " 'gan_generated_image_epoch_1.png'\n",
    " ]:\n",
    "  files.download(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rAwPqAIxdhAj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "GAN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
